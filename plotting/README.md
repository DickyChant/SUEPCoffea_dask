## Plotting for SUEP Analysis

### (Optional) Merge hdf5 files

Once you have produced the ntuples, your next step it to head to `plotting/` and make plots. However, since there are many hdf5 files for each dataset, reading in a large amount of files can be slow; we can thus merge these hdf5 files together into larger ones to reduce the amount of files to read in. This can be done using `merge_plots.py`, which is ran on one dataset, and `merge_all.py`, a wrapper for `merge_plots.py` to run it over many datasets. The syntax for this is

```
python merge_plots.py --dataset=<dataset> --tag=<tag> --isMC=<isMC>
```

N.B.: this is only set up to grab files from remote using XRootD, for now.
And the wrapper,

```
python multithread.py --tag=<tag> --code=merge  --inputList=<filelist>
```

### Producing the Plots

The plotting is to be done over the hdf5 ntuples produced by `workflows/SUEP_coffea.py`. This is achieved using `make_plots.py`, using the options as follows,

```
python make_plots.py --dataset <dataset> --output <output_tag> --tag <tag> --era <year> --isMC <bool> --doInf <bool> --doSyst <bool>
```

The expected structure of your data is: `/path/<tag>/<dataset>/`. The xrootd option tells the script whether you need xrootd to access the files, or whether they are stored locally. You might need to change the dataDir in the script for it to point to the correct spot.

To automatically run make_plots.py over all the \<dataset\>s, use mutlithreading:

```
python multithread.py --tag=<tag> --xrootd=0 --code=plot --inputList=<filelist>
```

This will parallelize the plotting for each dataset, producing one pkl file for each dataset.

### make_plots.py

The DataFrame generated by `../workflows/SUEP_coffea.py` has the form:

| event variables (ht, ...) | CL vars (SUEP_S1_CL, ...) | GNN vars (SUEP_S1_GNN, ...) | Other methods |
| ------------------------- | ------------------------- | --------------------------- | ------------- |
| 0.3                       | 0.73                      | 0.22                        | ...           |
| 1.1                       | 1.0                       | Nan                         | ...           |
| 0.8                       | Nan                       | 0.12                        | ...           |
| ...                       | ...                       | ...                         | ...           |

(The event variables are always filled, while the variables for each method are filled only if the event passes the method's selections, hence the `NaN`s).

The idea of this script is to map each of these methods to a set of histograms and fill them. Thus, for each input method, we define:

1. An output tag (e.g. input method: CL --> output tag Cluster)
2. **xvar/yvar**: x/y variables for ABCD method
3. **xvar_ragions/yvar_regions**: regions for ABCD method. N.B.: Include lower and upper bounds for all ABCD regions (e.g. `[0.0, 0.5, 1.0]`).
4. **SR**: signal region definition (e.g. `[['SUEP_S1_CL', '>=', 0.5], ['SUEP_nconst_CL', '>=', 80]]`)
5. **selections**: a set of selections (e.g. `[['ht', '>', 1200], ['ntracks','>', 0]]`)
   These are all defined in a dictionary, which is included in the `config` dictionary. Each own input methods have their own selections, ABCD regions, and signal region. Multiple output tags can be defined for the same input method: i.e. different selections, ABCD methods, and SRs can be defined.

This script will plot, for each 'label_out':

1. All event variables, e.g. ht_label_out
2. All columns from 'input_method', e.g. SUEP_S1_CL column will be plotted to histogram SUEP_S1_Cluster
3. 2D variables are automatically plotted

N.B.: Histograms are filled only if they are initialized in the output dictionary.

#### plotter

    1. Grab only events that don't have NaN for the input method variables.
    2. Blind for data! Use SR to define signal regions and cut it out of df.
    3. Apply selections as defined in the 'selections' in the dict.

#### auto_fill

    1. Plot variables from the DataFrame.
       1a. Event wide variables
       1b. Input method variables
    2. Plot 2D variables.
    3. Plot variables from the different ABCD regions as defined in the abcd dict.
       3a. Event wide variables
       3b. Input method variables

#### Weights, Cross sections, and Systematics

1. **xsection**: These are defined in `../data/xsections_{}.json` for each HT or pT bin/dataset, based on the era. These work with `gensumweight`, which is obtained from each hdf5 file's metadata, to scale that entire dataset by `xsection/total_weight`, where `total_weight` here is the sum of all the files `gensumweights`.
2. **pileup**: The weights are applied to MC based on the era only, they are applied based on the variable `Pileup_nTrueInt` directly to the events, and are defined in `pileup_weight.py`.
3. **track killing**:
4. **Pre shower weights**:
5. **GNN syst**:
6. **Higgs reweight**:
7. **Trigger scale factor**:
8. **ABCD weights**: These are weights that are defined based on each ABDC region (with the variables x_var, y_var) to force a third variable (z_var) to match for MC and data. These are produced in `plot.ipynb` and are saved as `.npy` files which are read in the script using `--weights=<file.npy>`.

### Plotting

The outputs of make_plots.py are .pkl files containing boost histograms. You can open these in your own scripts and notebooks to view them,
but a notebook, `plot.ipynb`, is provided with many useful functionalities. By specifying which pkl files you want to import using a tag,
the notebook will automatically load all the pkl files into one nested dictionary (`plots`), with dimensions (sample x plots),
where sample is either one of the \<dataset\>s, as well as all the combined QCD bins. Functions to plot in 1d and 2d, ratios of histograms,
plots by QCD bin, 1d slices of 2d hists, and other useful plotting functions are defined within.
